{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jeremy-feng/deep-learning-coursework/blob/main/2-BERT/BERT-QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# 作业2：对Bert进行微调，完成QA任务","metadata":{"id":"-XF4wAqb4yOr"}},{"cell_type":"markdown","source":"**如果你对Bert没有了解，请先观看视频 [BERT 论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1PL411M7eQ)**\n\n注：本次作业并不需要预先了解任何Transformer的知识，如有兴趣，可以在观看Bert的视频前，先预习 [Transformer论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1pu411o7BE)，后续课程中会讲解Transformer的知识。\n\n","metadata":{"id":"LeoLEi2r4yOt"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUrLd3HX71mx","outputId":"e2420273-e24c-40d4-9ceb-fef9785999bd","execution":{"iopub.status.busy":"2023-04-16T13:15:33.660297Z","iopub.execute_input":"2023-04-16T13:15:33.660689Z","iopub.status.idle":"2023-04-16T13:15:33.665643Z","shell.execute_reply.started":"2023-04-16T13:15:33.660652Z","shell.execute_reply":"2023-04-16T13:15:33.664442Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"id":"WG84QaHe4yOu","outputId":"9d4d1073-7a14-4c68-c8a0-bd5c1aec0443","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-04-16T13:15:33.668077Z","iopub.execute_input":"2023-04-16T13:15:33.668943Z","iopub.status.idle":"2023-04-16T13:15:34.708526Z","shell.execute_reply.started":"2023-04-16T13:15:33.668902Z","shell.execute_reply":"2023-04-16T13:15:34.707133Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nimport random\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n# Fix random seed for reproducibility\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n\nsame_seeds(0)","metadata":{"tags":[],"id":"261wXIir4yOv","execution":{"iopub.status.busy":"2023-04-16T13:15:34.711654Z","iopub.execute_input":"2023-04-16T13:15:34.712060Z","iopub.status.idle":"2023-04-16T13:15:34.721818Z","shell.execute_reply.started":"2023-04-16T13:15:34.712022Z","shell.execute_reply":"2023-04-16T13:15:34.720747Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/cmrc2018/train.json') as f:\n    train = json.load(f)\n\nwith open('/kaggle/input/cmrc2018/dev.json') as f:\n    dev = json.load(f)\n","metadata":{"id":"xDKJnLW24yOv","execution":{"iopub.status.busy":"2023-04-16T13:15:34.725463Z","iopub.execute_input":"2023-04-16T13:15:34.725848Z","iopub.status.idle":"2023-04-16T13:15:35.239204Z","shell.execute_reply.started":"2023-04-16T13:15:34.725820Z","shell.execute_reply":"2023-04-16T13:15:35.238152Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Let's have a glance at the data.","metadata":{"id":"aKFgHzeK4yOv"}},{"cell_type":"code","source":"!pip install transformers\nfrom transformers import BertTokenizerFast, BertForQuestionAnswering\n\n# You can explore more pretrained models from https://huggingface.co/models\n# 这段代码利用Hugging Face库中的BertTokenizerFast方法从预训练模型'bert-base-chinese'中加载tokenizer。\n# 这个预训练模型是一个中文BERT模型，可以将中文句子或文本数据转换为相应的token，以便进行文本分类、序列标注等自然语言处理任务。\n# BertTokenizerFast是BertTokenizer的升级版，速度更快，性能更优。\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\nmodel = BertForQuestionAnswering.from_pretrained('bert-base-chinese').to(device)\n\n# You can safely ignore the warning message (it pops up because new prediction heads for QA are initialized randomly)","metadata":{"tags":[],"id":"k8-oDM8-4yOv","outputId":"db5fc040-d3f0-49dc-9c88-3f671bb7a3cd","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-04-16T13:15:35.241131Z","iopub.execute_input":"2023-04-16T13:15:35.241904Z","iopub.status.idle":"2023-04-16T13:15:51.618255Z","shell.execute_reply.started":"2023-04-16T13:15:35.241861Z","shell.execute_reply":"2023-04-16T13:15:51.617147Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b23c557060ed467f97c81c5cf71c11b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bafd279c90af4dc6a4454eadc4aeff07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbbe05e6346c408ca13f101862318353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d563868e1eec40b08df9522b7ccef6e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/412M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2000a1f2766a40a6a54740859bebdd07"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## PreProcessing","metadata":{"id":"Zm-mWAfp4yOv"}},{"cell_type":"markdown","source":"### Prepare training data","metadata":{"id":"xWLFri4V4yOv"}},{"cell_type":"code","source":"paragraphs = []\nquestions = []\nstart_positions = []\nend_positions = []\nfor paragraph in train['data']:\n    for qa in paragraph['paragraphs'][0]['qas']:\n        \n        ### START CODE HERE ### \n        # For each question, add its paragraph, question, start_position and end_position(after calculation) to its corresponding list.\n        paragraphs.append(paragraph['paragraphs'][0]['context'])\n        questions.append(qa['question'])\n        start_position = qa['answers'][0]['answer_start']\n        start_positions.append(start_position)\n        anwser_length = len(qa['answers'][0]['text'])\n        end_positions.append(start_position + anwser_length)\n        ### END CODE HERE ###","metadata":{"id":"W4Vq3rCC4yOv","execution":{"iopub.status.busy":"2023-04-16T13:15:51.620234Z","iopub.execute_input":"2023-04-16T13:15:51.620599Z","iopub.status.idle":"2023-04-16T13:15:51.648477Z","shell.execute_reply.started":"2023-04-16T13:15:51.620566Z","shell.execute_reply":"2023-04-16T13:15:51.647524Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"questions[:5]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYpWVxhvE_5l","outputId":"55fa7c9d-1594-440d-c7e4-56581cb365d5","execution":{"iopub.status.busy":"2023-04-16T13:15:51.650090Z","iopub.execute_input":"2023-04-16T13:15:51.650489Z","iopub.status.idle":"2023-04-16T13:15:51.659895Z","shell.execute_reply.started":"2023-04-16T13:15:51.650450Z","shell.execute_reply":"2023-04-16T13:15:51.658684Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['范廷颂是什么时候被任为主教的？',\n '1990年，范廷颂担任什么职务？',\n '范廷颂是于何时何地出生的？',\n '1994年3月，范廷颂担任什么职务？',\n '范廷颂是何时去世的？']"},"metadata":{}}]},{"cell_type":"code","source":"start_positions[:5]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxwRkayQFGXR","outputId":"91fe224b-7871-4e6c-ef47-555cf471535a","execution":{"iopub.status.busy":"2023-04-16T13:15:51.661744Z","iopub.execute_input":"2023-04-16T13:15:51.662134Z","iopub.status.idle":"2023-04-16T13:15:51.672383Z","shell.execute_reply.started":"2023-04-16T13:15:51.662079Z","shell.execute_reply":"2023-04-16T13:15:51.671228Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[30, 41, 97, 548, 759]"},"metadata":{}}]},{"cell_type":"code","source":"end_positions[:5]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pshpsS3BFJFh","outputId":"3e1b98f9-bba9-4ceb-844b-2926d150828a","execution":{"iopub.status.busy":"2023-04-16T13:15:51.673697Z","iopub.execute_input":"2023-04-16T13:15:51.674557Z","iopub.status.idle":"2023-04-16T13:15:51.683299Z","shell.execute_reply.started":"2023-04-16T13:15:51.674518Z","shell.execute_reply":"2023-04-16T13:15:51.682166Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[35, 62, 126, 598, 780]"},"metadata":{}}]},{"cell_type":"markdown","source":"查看第 3 个问题的回答是否正确","metadata":{"id":"LbQdrGUFilrE"}},{"cell_type":"code","source":"paragraphs[0][start_positions[2]: end_positions[2]]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hXwZrYtQiqWY","outputId":"623bcfb6-869c-43df-f815-3d941b741cb2","execution":{"iopub.status.busy":"2023-04-16T13:15:51.688545Z","iopub.execute_input":"2023-04-16T13:15:51.689187Z","iopub.status.idle":"2023-04-16T13:15:51.695575Z","shell.execute_reply.started":"2023-04-16T13:15:51.689143Z","shell.execute_reply":"2023-04-16T13:15:51.694534Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'范廷颂于1919年6月15日在越南宁平省天主教发艳教区出生'"},"metadata":{}}]},{"cell_type":"markdown","source":"将 paragraphs 和 questions 进行 encoding。\n参考：[https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__)","metadata":{"id":"aAf1IrcPGGch"}},{"cell_type":"code","source":"# 下面这段代码使用了 Hugging Face 的 tokenizer 方法，将 paragraphs 和 questions 转换成相应的 token，\n# 返回一个字典 (train_encodings) 包含这些 token 的各种信息，这些信息包括 input_ids、attention_mask 等等。\n# return_tensors='pt' 表示返回 PyTorch 下的 tensor 格式\n# padding 用于填充不足 max_length 的 token\n# truncation 用于在超过 max_length 时截断 token\n# 最终的 token 长度被限制在 512 内\ntrain_encodings = tokenizer(\n    paragraphs,\n    questions,\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True,\n    max_length=512,\n)\n","metadata":{"tags":[],"id":"BtlaETbX4yOw","execution":{"iopub.status.busy":"2023-04-16T13:15:51.697203Z","iopub.execute_input":"2023-04-16T13:15:51.697916Z","iopub.status.idle":"2023-04-16T13:16:00.426385Z","shell.execute_reply.started":"2023-04-16T13:15:51.697877Z","shell.execute_reply":"2023-04-16T13:16:00.425333Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_encodings.keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQAzqnsvIFqD","outputId":"1fa893cf-ed13-478f-b2f9-5e2ffe9b0475","execution":{"iopub.status.busy":"2023-04-16T13:16:00.430653Z","iopub.execute_input":"2023-04-16T13:16:00.430961Z","iopub.status.idle":"2023-04-16T13:16:00.438067Z","shell.execute_reply.started":"2023-04-16T13:16:00.430930Z","shell.execute_reply":"2023-04-16T13:16:00.437020Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"markdown","source":"- 在问答任务中，`input_ids` 是将输入文本转换为整数序列后的输出。它将每个单词或子词映射到一个唯一的整数 ID, 位于 [CLS] 和 [SEP] 标记会被分别映射到一个特殊的 ID，(101: CLS, 102: SEP)。具体可以参考下方例子。\n\n- 在 `token_type_ids` 中，这些标记的值通常为 0 或 1，其中 0 表示该 token 属于第一个文本序列（通常是问题），1 表示该 token 属于第二个文本序列（通常是段落）。\n\n- 在 `attention_mask` 中，0 表示对应的标记应该被忽略，1 表示对应的标记应该被关注。当输入序列长度不足最大长度时，我们需要在序列末尾填充一些无意义的标记，以使序列长度达到最大长度。在这种情况下，`tokenizer`将填充的标记的 attention mask 设置为 0，以告诉模型它们不应该被关注。","metadata":{"id":"lX4vyeGS4yOw"}},{"cell_type":"code","source":"a = tokenizer(\n    paragraphs[0],\n    questions[0],\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True,\n    max_length=512,\n)['input_ids'][0]","metadata":{"id":"ZeEfNKVyWAen","execution":{"iopub.status.busy":"2023-04-16T13:16:00.439870Z","iopub.execute_input":"2023-04-16T13:16:00.440616Z","iopub.status.idle":"2023-04-16T13:16:01.089816Z","shell.execute_reply.started":"2023-04-16T13:16:00.440554Z","shell.execute_reply":"2023-04-16T13:16:01.088551Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"b = tokenizer(\n    paragraphs[0],\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True,\n    max_length=512,\n)['input_ids'][0]","metadata":{"id":"CQbP9QEJZ-xS","execution":{"iopub.status.busy":"2023-04-16T13:16:01.091526Z","iopub.execute_input":"2023-04-16T13:16:01.092160Z","iopub.status.idle":"2023-04-16T13:16:01.102529Z","shell.execute_reply.started":"2023-04-16T13:16:01.092095Z","shell.execute_reply":"2023-04-16T13:16:01.101529Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode([711, 1921,  712, 3136, 3777, 1079, 2600, 3136, 1277,\n        2134, 2429, 5392,  102, 5745, 2455, 7563, 3221,  784,  720, 3198,  952,\n        6158,  818,  711,  712, 3136, 4638, 8043,  102])","metadata":{"tags":[],"id":"-TCD9U374yOw","outputId":"d6b6733b-df66-4150-e6c1-7648e6f013ad","colab":{"base_uri":"https://localhost:8080/","height":35},"execution":{"iopub.status.busy":"2023-04-16T13:16:01.104241Z","iopub.execute_input":"2023-04-16T13:16:01.104990Z","iopub.status.idle":"2023-04-16T13:16:06.794338Z","shell.execute_reply.started":"2023-04-16T13:16:01.104941Z","shell.execute_reply":"2023-04-16T13:16:06.793154Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'为 天 主 教 河 内 总 教 区 宗 座 署 [SEP] 范 廷 颂 是 什 么 时 候 被 任 为 主 教 的 ？ [SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"len([5745, 2455, 7563, 3221,  784,  720, 3198,  952,\n        6158,  818,  711,  712, 3136, 4638, 8043,  102])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l80_9ZsedeMq","outputId":"2570c87a-4ba7-428b-a10b-d290645de170","execution":{"iopub.status.busy":"2023-04-16T13:16:06.796051Z","iopub.execute_input":"2023-04-16T13:16:06.796445Z","iopub.status.idle":"2023-04-16T13:16:06.805314Z","shell.execute_reply.started":"2023-04-16T13:16:06.796405Z","shell.execute_reply":"2023-04-16T13:16:06.804135Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"16"},"metadata":{}}]},{"cell_type":"markdown","source":"最后 16 个元素为 1，这说明最后 16 个 token 对应的是 question","metadata":{"id":"2knZqNTO6ePb"}},{"cell_type":"code","source":"train_encodings['token_type_ids'][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJ9lOj7vdqkS","outputId":"7dc3b5c1-e3ec-4dd2-fc34-bfcecf168cca","execution":{"iopub.status.busy":"2023-04-16T13:16:06.807064Z","iopub.execute_input":"2023-04-16T13:16:06.807481Z","iopub.status.idle":"2023-04-16T13:16:06.826689Z","shell.execute_reply.started":"2023-04-16T13:16:06.807435Z","shell.execute_reply":"2023-04-16T13:16:06.825465Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings['token_type_ids'][0].sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHmjrpNqdgV3","outputId":"b3483015-f0f5-40f1-977c-5fa58ab8d191","execution":{"iopub.status.busy":"2023-04-16T13:16:06.828600Z","iopub.execute_input":"2023-04-16T13:16:06.828963Z","iopub.status.idle":"2023-04-16T13:16:06.838665Z","shell.execute_reply.started":"2023-04-16T13:16:06.828925Z","shell.execute_reply":"2023-04-16T13:16:06.837488Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"tensor(16)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode([711, 1921,  712, 3136, 3777, 1079, 2600, 3136, 1277,\n        2134, 2429, 5392, 4415,  809, 1856, 6133, 6421, 3136, 1277, 2600,  712,\n        3136, 4638, 4958, 5375,  511, 8447, 2399,  102])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"seEeGEBLdDsp","outputId":"ce72ea78-62e5-43d4-c73d-d7e961ed543e","execution":{"iopub.status.busy":"2023-04-16T13:16:06.840297Z","iopub.execute_input":"2023-04-16T13:16:06.841400Z","iopub.status.idle":"2023-04-16T13:16:06.849722Z","shell.execute_reply.started":"2023-04-16T13:16:06.841362Z","shell.execute_reply":"2023-04-16T13:16:06.848559Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'为 天 主 教 河 内 总 教 区 宗 座 署 理 以 填 补 该 教 区 总 主 教 的 空 缺 。 1994 年 [SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings['token_type_ids']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izDDbdndLW9m","outputId":"02ee7315-cdee-4b11-8694-b48f44e1af18","execution":{"iopub.status.busy":"2023-04-16T13:16:06.851359Z","iopub.execute_input":"2023-04-16T13:16:06.851792Z","iopub.status.idle":"2023-04-16T13:16:06.870032Z","shell.execute_reply.started":"2023-04-16T13:16:06.851740Z","shell.execute_reply":"2023-04-16T13:16:06.869128Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"tensor([[0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 1, 1, 1],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"print(train_encodings['input_ids'].shape)\nprint(train_encodings['token_type_ids'].shape)\nprint(train_encodings['attention_mask'].shape)","metadata":{"tags":[],"id":"dimamZ1Q4yOw","outputId":"78491690-7b59-47a3-9c13-6b83f39847b2","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-04-16T13:16:06.871538Z","iopub.execute_input":"2023-04-16T13:16:06.871906Z","iopub.status.idle":"2023-04-16T13:16:06.877906Z","shell.execute_reply.started":"2023-04-16T13:16:06.871869Z","shell.execute_reply":"2023-04-16T13:16:06.876808Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"torch.Size([10142, 512])\ntorch.Size([10142, 512])\ntorch.Size([10142, 512])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"下面的代码的作用是：将 answer 在原始 paragrapgh 的起止索引，转换为在经过tokenizor 之后点 input_ids 中的起止索引","metadata":{"id":"nok-nu4jg6Av"}},{"cell_type":"code","source":"# `char_to_token` will convert answer's start/end positions in paragraph_text to start/end positions in tokenized_paragraph  \ntrain_encodings['start_positions'] = torch.tensor([train_encodings.char_to_token(idx, x) if train_encodings.char_to_token(idx, x) != None else -1\n                                      for idx, x in enumerate(start_positions)])\ntrain_encodings['end_positions'] = torch.tensor([train_encodings.char_to_token(idx, x-1) if train_encodings.char_to_token(idx, x-1) != None else -1\n                                    for idx, x in enumerate(end_positions)])","metadata":{"id":"xPfmrljfKmal","execution":{"iopub.status.busy":"2023-04-16T13:16:06.879380Z","iopub.execute_input":"2023-04-16T13:16:06.880278Z","iopub.status.idle":"2023-04-16T13:16:06.952036Z","shell.execute_reply.started":"2023-04-16T13:16:06.880230Z","shell.execute_reply":"2023-04-16T13:16:06.951019Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_encodings['start_positions']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ok3cM76hjDc","outputId":"e2aae299-28ef-4f81-8462-a0e446af859d","execution":{"iopub.status.busy":"2023-04-16T13:16:06.953548Z","iopub.execute_input":"2023-04-16T13:16:06.953913Z","iopub.status.idle":"2023-04-16T13:16:06.962057Z","shell.execute_reply.started":"2023-04-16T13:16:06.953879Z","shell.execute_reply":"2023-04-16T13:16:06.960802Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensor([ 31,  39,  86,  ..., 142, 225,  17])"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings['end_positions']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCjrEnwghkpZ","outputId":"c27374e8-c216-40bd-d7b2-06dd55b66f03","execution":{"iopub.status.busy":"2023-04-16T13:16:06.964018Z","iopub.execute_input":"2023-04-16T13:16:06.964927Z","iopub.status.idle":"2023-04-16T13:16:06.972206Z","shell.execute_reply.started":"2023-04-16T13:16:06.964889Z","shell.execute_reply":"2023-04-16T13:16:06.971001Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"tensor([ 32,  56, 110,  ..., 143, 244,  19])"},"metadata":{}}]},{"cell_type":"markdown","source":"以第 3 个问题为例，即以 86 和 110 作为起止索引为例，查看它们对应的字符串是什么","metadata":{"id":"covx-s_zh_Fk"}},{"cell_type":"code","source":"questions[2]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2MVfIHvSiRgF","outputId":"ad66e184-6550-4ed2-c33f-17f0e211aa5c","execution":{"iopub.status.busy":"2023-04-16T13:16:06.973971Z","iopub.execute_input":"2023-04-16T13:16:06.974418Z","iopub.status.idle":"2023-04-16T13:16:06.981966Z","shell.execute_reply.started":"2023-04-16T13:16:06.974381Z","shell.execute_reply":"2023-04-16T13:16:06.980811Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'范廷颂是于何时何地出生的？'"},"metadata":{}}]},{"cell_type":"code","source":"paragraphs[0][start_positions[2]: end_positions[2]]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"LcgO8Dk6hynX","outputId":"597a27a9-1641-45f1-9cf4-1ed6c1e7bdef","execution":{"iopub.status.busy":"2023-04-16T13:16:06.983568Z","iopub.execute_input":"2023-04-16T13:16:06.984472Z","iopub.status.idle":"2023-04-16T13:16:06.993522Z","shell.execute_reply.started":"2023-04-16T13:16:06.984431Z","shell.execute_reply":"2023-04-16T13:16:06.991122Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'范廷颂于1919年6月15日在越南宁平省天主教发艳教区出生'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(train_encodings['input_ids'][0][86: 110+1])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"J5mqFCD3horn","outputId":"d1082623-4bdf-4313-e7de-62df3b0270a6","execution":{"iopub.status.busy":"2023-04-16T13:16:06.994926Z","iopub.execute_input":"2023-04-16T13:16:06.995323Z","iopub.status.idle":"2023-04-16T13:16:07.003956Z","shell.execute_reply.started":"2023-04-16T13:16:06.995293Z","shell.execute_reply":"2023-04-16T13:16:07.002047Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'范 廷 颂 于 1919 年 6 月 15 日 在 越 南 宁 平 省 天 主 教 发 艳 教 区 出 生'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Prepare Dataset","metadata":{"id":"LBxjey-94yOw"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n    \nimport torch\n\nclass SquadDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {k: v[idx].to(device) for k, v in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\ntrain_dataset = SquadDataset(train_encodings)","metadata":{"tags":[],"id":"n6j6_ndI4yOw","execution":{"iopub.status.busy":"2023-04-16T13:16:07.012436Z","iopub.execute_input":"2023-04-16T13:16:07.013283Z","iopub.status.idle":"2023-04-16T13:16:07.020508Z","shell.execute_reply.started":"2023-04-16T13:16:07.013236Z","shell.execute_reply":"2023-04-16T13:16:07.019392Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Automatic Mixed Precision (AMP) is available on NVIDIA GPUs that support Tensor Cores, which are specialized hardware units for performing fast matrix multiplication and convolution operations in deep learning. Specifically, Tensor Cores are available on NVIDIA Volta, Turing, and Ampere architectures, which include the following GPU series:\n\n- Volta: Tesla V100, Titan V\n- Turing: Quadro RTX, GeForce RTX 20-series, Titan RTX\n- Ampere: A100, GeForce RTX 30-series, Titan RTX","metadata":{"id":"UrtMKHnx4yOw"}},{"cell_type":"code","source":"# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\nfp16_training = True\n\nif fp16_training:\n    !pip install accelerate\n    from accelerate import Accelerator\n\n    accelerator = Accelerator()\n    device = accelerator.device\n\n# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/","metadata":{"tags":[],"id":"renVJ9D-4yOx","outputId":"4b99918d-b02b-4a82-93cb-16cf3cedd169","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-04-16T13:16:07.021986Z","iopub.execute_input":"2023-04-16T13:16:07.022711Z","iopub.status.idle":"2023-04-16T13:16:17.034569Z","shell.execute_reply.started":"2023-04-16T13:16:07.022673Z","shell.execute_reply":"2023-04-16T13:16:17.033313Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.13.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.21.6)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (23.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4.0->accelerate) (4.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFviEE_F8oii","outputId":"07889db5-1aaf-4f2c-c1a2-455f1d966114","execution":{"iopub.status.busy":"2023-04-16T13:16:17.037591Z","iopub.execute_input":"2023-04-16T13:16:17.038019Z","iopub.status.idle":"2023-04-16T13:16:17.046018Z","shell.execute_reply.started":"2023-04-16T13:16:17.037971Z","shell.execute_reply":"2023-04-16T13:16:17.044927Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"next(model.parameters())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vaFhtF97-glu","outputId":"29e80e84-e934-40d2-d145-9f8894b0db1e","execution":{"iopub.status.busy":"2023-04-16T13:16:17.047392Z","iopub.execute_input":"2023-04-16T13:16:17.047706Z","iopub.status.idle":"2023-04-16T13:16:18.689180Z","shell.execute_reply.started":"2023-04-16T13:16:17.047677Z","shell.execute_reply":"2023-04-16T13:16:18.688077Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Parameter containing:\ntensor([[ 0.0262,  0.0109, -0.0187,  ...,  0.0903,  0.0028,  0.0064],\n        [ 0.0021,  0.0216,  0.0011,  ...,  0.0809,  0.0018,  0.0249],\n        [ 0.0147,  0.0005,  0.0028,  ...,  0.0836,  0.0121,  0.0282],\n        ...,\n        [ 0.0346,  0.0021,  0.0085,  ...,  0.0085,  0.0337,  0.0099],\n        [ 0.0541,  0.0289,  0.0263,  ...,  0.0526,  0.0651,  0.0353],\n        [ 0.0200,  0.0023, -0.0089,  ...,  0.0799, -0.0562,  0.0247]],\n       device='cuda:0', requires_grad=True)"},"metadata":{}}]},{"cell_type":"code","source":"next(model.parameters()).shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdMC5I8d-Jyt","outputId":"9cb111c5-7ee5-4b23-d9e4-5824ed2bd5d8","execution":{"iopub.status.busy":"2023-04-16T13:16:18.690509Z","iopub.execute_input":"2023-04-16T13:16:18.691178Z","iopub.status.idle":"2023-04-16T13:16:18.699814Z","shell.execute_reply.started":"2023-04-16T13:16:18.691135Z","shell.execute_reply":"2023-04-16T13:16:18.698784Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"torch.Size([21128, 768])"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\n### START CODE HERE ### \n# Use AdamW as the optimizer, and learning rate 5e-5.\n# https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html\noptim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n### END CODE HERE ### \n","metadata":{"tags":[],"id":"rmerLUao4yOx","execution":{"iopub.status.busy":"2023-04-16T13:16:18.701601Z","iopub.execute_input":"2023-04-16T13:16:18.701985Z","iopub.status.idle":"2023-04-16T13:16:18.711028Z","shell.execute_reply.started":"2023-04-16T13:16:18.701944Z","shell.execute_reply":"2023-04-16T13:16:18.710034Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model, optim, train_loader = accelerator.prepare(model, optim, train_loader)","metadata":{"id":"y5zUdeMdAjOz","execution":{"iopub.status.busy":"2023-04-16T13:16:18.712581Z","iopub.execute_input":"2023-04-16T13:16:18.713008Z","iopub.status.idle":"2023-04-16T13:16:18.729565Z","shell.execute_reply.started":"2023-04-16T13:16:18.712971Z","shell.execute_reply":"2023-04-16T13:16:18.728514Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.train()\nloss_sum = 0.0\nacc_start_sum = 0.0\nacc_end_sum = 0.0","metadata":{"id":"ehKlMKzzAjtn","execution":{"iopub.status.busy":"2023-04-16T13:16:18.731135Z","iopub.execute_input":"2023-04-16T13:16:18.731616Z","iopub.status.idle":"2023-04-16T13:16:18.738949Z","shell.execute_reply.started":"2023-04-16T13:16:18.731577Z","shell.execute_reply":"2023-04-16T13:16:18.737898Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for batch_idx, batch in enumerate(tqdm(train_loader)):\n    print(batch_idx, batch)\n    break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnjdfXlsAnyy","outputId":"b32dbf64-6b10-4b0b-ce3e-c9634699de38","execution":{"iopub.status.busy":"2023-04-16T13:16:18.740659Z","iopub.execute_input":"2023-04-16T13:16:18.741086Z","iopub.status.idle":"2023-04-16T13:16:18.767377Z","shell.execute_reply.started":"2023-04-16T13:16:18.741050Z","shell.execute_reply":"2023-04-16T13:16:18.766360Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"  0%|          | 0/1268 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"0 {'input_ids': tensor([[ 101, 1102, 3777,  ...,    0,    0,    0],\n        [ 101, 6437, 1923,  ...,    0,    0,    0],\n        [ 101, 4549, 4565,  ..., 4638, 8043,  102],\n        ...,\n        [ 101, 7032, 7305,  ...,  763, 8043,  102],\n        [ 101, 7942, 6586,  ...,    0,    0,    0],\n        [ 101, 4482, 3419,  ...,    0,    0,    0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 1, 1, 1],\n        ...,\n        [0, 0, 0,  ..., 1, 1, 1],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'start_positions': tensor([ 38, 108,  19,  81,  10, 330, 204,  12], device='cuda:0'), 'end_positions': tensor([ 47, 131,  20,  86,  17, 346, 240,  22], device='cuda:0')}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_idx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-guALDwAr03","outputId":"4514bf48-defa-4e87-e793-8301927c23c5","execution":{"iopub.status.busy":"2023-04-16T13:16:18.768603Z","iopub.execute_input":"2023-04-16T13:16:18.769673Z","iopub.status.idle":"2023-04-16T13:16:18.776353Z","shell.execute_reply.started":"2023-04-16T13:16:18.769636Z","shell.execute_reply":"2023-04-16T13:16:18.775154Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"由于 train_loader 设置了 batch_size=8，因此这里每一个批次包含 8 个数据\n\n","metadata":{"id":"xSup9yI_BtYa"}},{"cell_type":"code","source":"batch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGq5IQyfBFo3","outputId":"4b263c75-399e-4f20-a394-582c38bf0feb","execution":{"iopub.status.busy":"2023-04-16T13:16:18.778275Z","iopub.execute_input":"2023-04-16T13:16:18.779026Z","iopub.status.idle":"2023-04-16T13:16:18.792392Z","shell.execute_reply.started":"2023-04-16T13:16:18.778989Z","shell.execute_reply":"2023-04-16T13:16:18.791704Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 101, 1102, 3777,  ...,    0,    0,    0],\n         [ 101, 6437, 1923,  ...,    0,    0,    0],\n         [ 101, 4549, 4565,  ..., 4638, 8043,  102],\n         ...,\n         [ 101, 7032, 7305,  ...,  763, 8043,  102],\n         [ 101, 7942, 6586,  ...,    0,    0,    0],\n         [ 101, 4482, 3419,  ...,    0,    0,    0]], device='cuda:0'),\n 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 1, 1, 1],\n         ...,\n         [0, 0, 0,  ..., 1, 1, 1],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'),\n 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 1, 1, 1],\n         ...,\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n 'start_positions': tensor([ 38, 108,  19,  81,  10, 330, 204,  12], device='cuda:0'),\n 'end_positions': tensor([ 47, 131,  20,  86,  17, 346, 240,  22], device='cuda:0')}"},"metadata":{}}]},{"cell_type":"code","source":"optim.zero_grad()","metadata":{"id":"KNMkO5oYCU30","execution":{"iopub.status.busy":"2023-04-16T13:16:18.793652Z","iopub.execute_input":"2023-04-16T13:16:18.794268Z","iopub.status.idle":"2023-04-16T13:16:18.799216Z","shell.execute_reply.started":"2023-04-16T13:16:18.794223Z","shell.execute_reply":"2023-04-16T13:16:18.798118Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"input_ids = batch['input_ids']\nattention_mask = batch['attention_mask']\nstart_positions = batch['start_positions']\nend_positions = batch['end_positions']\n\noutputs = model(input_ids, attention_mask=attention_mask, \n                start_positions=start_positions, \n                end_positions=end_positions)","metadata":{"id":"GuPEKq_DCXs2","execution":{"iopub.status.busy":"2023-04-16T13:16:18.800743Z","iopub.execute_input":"2023-04-16T13:16:18.801392Z","iopub.status.idle":"2023-04-16T13:16:20.407606Z","shell.execute_reply.started":"2023-04-16T13:16:18.801355Z","shell.execute_reply":"2023-04-16T13:16:20.406503Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eH2jT4s7Ccy9","outputId":"37109c11-231e-49ab-8469-3ed74c100d66","execution":{"iopub.status.busy":"2023-04-16T13:16:20.409182Z","iopub.execute_input":"2023-04-16T13:16:20.410345Z","iopub.status.idle":"2023-04-16T13:16:20.513846Z","shell.execute_reply.started":"2023-04-16T13:16:20.410302Z","shell.execute_reply":"2023-04-16T13:16:20.512803Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"QuestionAnsweringModelOutput(loss=tensor(6.3567, device='cuda:0', grad_fn=<DivBackward0>), start_logits=tensor([[-0.0901, -0.0449,  0.6937,  ...,  0.1636,  0.2241,  0.0975],\n        [-0.1821, -0.4386,  0.1097,  ..., -0.1325, -0.3646, -0.2178],\n        [-0.1493, -0.1064,  0.2222,  ...,  0.2401,  0.1956,  0.3059],\n        ...,\n        [ 0.2721,  0.1159,  0.1111,  ...,  0.5787,  0.5692,  0.2100],\n        [-0.1677,  0.0131,  0.3072,  ..., -0.1343, -0.0099, -0.1005],\n        [ 0.0869, -0.1847,  0.7930,  ..., -0.1804, -0.2160, -0.2182]],\n       device='cuda:0', grad_fn=<CloneBackward0>), end_logits=tensor([[ 0.6159,  0.2972, -0.0280,  ...,  0.1095, -0.1247,  0.1841],\n        [ 0.6317,  0.4158, -0.6848,  ..., -0.0872, -0.0054,  0.0493],\n        [ 0.6075,  0.3280, -0.6157,  ..., -0.5438,  0.6205,  0.2260],\n        ...,\n        [ 0.6398,  0.2011, -0.3014,  ..., -0.2863,  0.5134,  0.3975],\n        [ 0.1596,  0.6876, -0.4636,  ..., -0.1172, -0.1384, -0.1386],\n        [ 0.5356,  0.5155, -0.3263,  ..., -0.1339, -0.1973, -0.0052]],\n       device='cuda:0', grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"loss = outputs.loss","metadata":{"id":"UY1BDazICsjQ","execution":{"iopub.status.busy":"2023-04-16T13:16:20.515337Z","iopub.execute_input":"2023-04-16T13:16:20.515924Z","iopub.status.idle":"2023-04-16T13:16:20.521961Z","shell.execute_reply.started":"2023-04-16T13:16:20.515883Z","shell.execute_reply":"2023-04-16T13:16:20.520773Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"loss","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVz5XXcMCt0n","outputId":"91839d86-9bd2-4bf3-b07e-a623d7f413d4","execution":{"iopub.status.busy":"2023-04-16T13:16:20.523428Z","iopub.execute_input":"2023-04-16T13:16:20.523854Z","iopub.status.idle":"2023-04-16T13:16:20.534376Z","shell.execute_reply.started":"2023-04-16T13:16:20.523814Z","shell.execute_reply":"2023-04-16T13:16:20.533146Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"tensor(6.3567, device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"accelerator.backward(loss)","metadata":{"id":"K8zfgU2fCyn6","execution":{"iopub.status.busy":"2023-04-16T13:16:20.536296Z","iopub.execute_input":"2023-04-16T13:16:20.536676Z","iopub.status.idle":"2023-04-16T13:16:20.826474Z","shell.execute_reply.started":"2023-04-16T13:16:20.536639Z","shell.execute_reply":"2023-04-16T13:16:20.825372Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"optim.step()","metadata":{"id":"DFWK6kxKC008","execution":{"iopub.status.busy":"2023-04-16T13:16:20.829209Z","iopub.execute_input":"2023-04-16T13:16:20.829590Z","iopub.status.idle":"2023-04-16T13:16:20.868575Z","shell.execute_reply.started":"2023-04-16T13:16:20.829551Z","shell.execute_reply":"2023-04-16T13:16:20.867510Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"loss_sum += loss.item()","metadata":{"id":"fqULWs1MC48Z","execution":{"iopub.status.busy":"2023-04-16T13:16:20.870557Z","iopub.execute_input":"2023-04-16T13:16:20.870955Z","iopub.status.idle":"2023-04-16T13:16:20.876025Z","shell.execute_reply.started":"2023-04-16T13:16:20.870916Z","shell.execute_reply":"2023-04-16T13:16:20.874903Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"对于第一个问答，输出每个 token 作为 start 的 logit，其值越大，说明越有可能作为 start","metadata":{"id":"VsGgLXaJFAE8"}},{"cell_type":"code","source":"outputs.start_logits[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLtJO3k6Eic_","outputId":"32d7a3d7-5de0-4184-aed7-11e3de433b14","execution":{"iopub.status.busy":"2023-04-16T13:16:20.877557Z","iopub.execute_input":"2023-04-16T13:16:20.878595Z","iopub.status.idle":"2023-04-16T13:16:20.898052Z","shell.execute_reply.started":"2023-04-16T13:16:20.878556Z","shell.execute_reply":"2023-04-16T13:16:20.897061Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"tensor([-0.0901, -0.0449,  0.6937,  0.2657,  0.5751,  0.2879,  0.5472,  0.5595,\n         0.3849,  0.4474,  0.0366,  0.2149,  0.3718,  0.5434,  0.4492,  0.8463,\n         0.5935,  0.1225,  0.0525,  0.2413,  0.2997,  0.3549,  1.1205,  0.2727,\n        -0.0344,  0.4527,  0.2076, -0.0130,  0.3765, -0.1353, -0.5382,  0.1187,\n        -0.3140,  0.6122,  0.0115, -0.0217,  0.0154,  0.0155,  0.2311,  0.1784,\n        -0.1717,  0.7615,  0.0560,  0.2829, -0.6343, -0.8912,  0.0342, -0.0572,\n         0.2255,  0.3893,  0.1140,  0.4778,  0.3645,  0.4438,  0.4550,  0.2165,\n        -0.5609, -0.3129, -0.0089,  0.2255,  0.3166,  0.2603, -0.8078, -0.2189,\n         0.2226, -0.1790, -0.1002,  0.4215, -0.1709,  0.3791,  0.0687, -0.4009,\n         0.6916,  0.4439,  0.4447,  0.2035,  0.3343,  0.3576,  0.5502,  0.7318,\n         0.3264, -0.3437, -0.5790,  0.0566, -0.3126, -0.2780, -0.2532,  0.4423,\n         0.4679,  0.5663,  0.1061, -0.1086,  0.1776,  0.6165,  0.1101,  0.2595,\n         0.5955,  0.2147,  0.2232, -0.1573, -0.1849, -0.1694, -0.4565, -0.1218,\n        -0.4673, -0.0196,  0.4703, -0.5803, -0.3572,  0.3456, -0.0252,  0.4786,\n         0.2660, -0.1526, -0.6809,  0.7982,  0.3548, -0.5111, -0.5945, -0.2056,\n         0.3027,  0.0431,  0.1084,  0.1985,  0.2663,  0.6551,  0.0339,  0.1131,\n         0.2565,  0.4918,  0.3320, -0.1790,  0.1993,  0.5605,  0.4207,  0.1749,\n         0.2235,  0.2952, -0.1165, -0.2965, -0.6902, -0.1712,  0.1447,  0.3512,\n         0.3096,  0.0116, -0.2678, -0.9558, -0.4564, -0.6341, -0.4697, -0.0537,\n         0.0665, -0.3492, -0.0104, -0.0551,  0.0991, -0.6752, -0.5959, -0.0876,\n        -0.3519, -0.0709,  0.1416,  0.4765, -0.2915, -0.2343,  0.0588, -0.7165,\n        -0.3072, -0.0652,  0.2018,  0.4103,  0.0344,  0.3690,  0.6131,  0.6353,\n         0.5358, -0.0351,  0.4092,  0.2907,  0.4123,  0.1483,  0.4703,  0.1341,\n        -0.2316,  0.3304,  0.3715,  0.5235,  0.1832, -0.0439, -0.2778,  0.0097,\n         0.2648,  0.0880,  0.2119,  0.1716,  0.3822,  0.4866,  0.6349,  0.4426,\n         0.2703,  0.0642,  0.2463,  0.5319,  0.5483,  0.2190, -0.0906, -0.3704,\n         0.2057,  0.1772,  0.1983,  0.0748,  0.4997,  0.1948, -0.0033,  0.1737,\n        -0.0292, -0.5439,  0.0945,  0.0739,  0.6598,  0.5914, -0.1315,  0.1107,\n         0.4888, -0.3082, -0.0241, -0.0035,  0.7553,  0.4269,  0.0422,  0.5486,\n         0.8629, -0.1512,  0.3882,  0.1122,  0.1197, -1.0094, -0.3846, -0.2014,\n         0.3931,  0.4712, -0.1587, -0.5289,  0.2411, -0.0163, -0.4368,  0.2915,\n        -0.4442, -0.4723,  0.2358, -0.1914, -0.1579,  0.0383,  0.5725,  0.1354,\n        -0.0280,  0.0811, -0.0647,  0.1363,  0.5187,  0.6818,  0.0142,  0.3879,\n         0.6426,  0.3179, -0.2734, -0.3082, -0.2359,  0.3340,  0.2661,  0.1258,\n         0.0368,  0.5957, -0.2720,  0.1497,  0.3581,  0.3157, -0.3338,  0.6789,\n         1.0089,  0.5331,  0.3881,  0.1678,  0.6029,  0.1025,  0.5858,  0.8910,\n        -0.0270,  0.1718,  0.7549,  0.1546,  0.4012,  0.5976,  0.6974,  0.2824,\n         0.2732,  0.0475,  0.2284,  0.4530,  0.1754,  0.4508, -0.2019,  0.6146,\n         0.3216,  0.3101,  0.6668,  0.4651,  0.8233, -0.1143,  0.2260,  0.3918,\n         0.3433,  0.5952,  0.8138,  0.1005, -0.1656, -0.2474,  0.4196,  0.6429,\n         0.3496,  0.4762,  0.3516, -0.1222, -0.2450,  0.0335,  0.1875, -0.1844,\n         0.0477,  0.6011, -0.2193, -0.4832,  0.1970,  0.1163,  0.4417,  0.1278,\n         0.5225,  0.8113, -0.1518, -0.0823,  0.2533,  0.3584,  0.8133, -0.0289,\n        -0.2566, -0.4287,  0.6052,  0.0724, -0.1438,  0.0195,  0.4532, -0.2582,\n        -0.6446,  0.2090,  0.4403,  0.7844,  0.2903, -0.1599, -0.5315,  0.2985,\n         0.6956,  0.8404,  0.3855,  0.0093,  0.5091,  0.3101,  0.0634,  0.3885,\n         0.4701, -0.0467,  0.4644, -0.0424,  0.1054, -0.0876, -0.3935,  0.0258,\n         0.2908,  0.4049,  0.4597,  0.1694,  0.2886, -0.2612,  0.2996,  0.2188,\n        -0.2175, -0.6413, -0.4348, -0.0717, -0.1221, -0.0818,  0.1741,  0.1534,\n        -0.1857, -0.3315, -0.2100,  0.1082,  0.1680, -0.1965,  0.7825,  0.2768,\n         0.6479, -0.4834, -0.0803,  0.3505,  0.0014,  0.3896, -0.4775, -0.1328,\n        -0.1201, -0.5057, -0.4266, -0.5591, -0.0597,  0.1998,  0.0878, -0.4628,\n         0.1142,  0.1750, -0.1903,  0.2194,  0.1489,  0.3256,  0.0334,  0.2223,\n         0.3186, -0.4296, -0.1674,  0.5228,  0.3397,  0.9870, -0.1057,  0.4844,\n         0.2027, -0.1453,  0.0290,  0.5287,  0.3796,  0.0449,  0.6656, -0.3743,\n        -0.4408,  0.1990,  0.4346, -0.0961, -0.2207,  0.8583,  0.6959,  0.1308,\n         0.4076, -0.4070,  0.2738, -0.3319, -0.2734, -0.0299,  0.8423,  0.1788,\n         0.1306,  0.0116,  0.3850,  0.5243,  1.0269,  0.0561,  0.4539,  0.2964,\n         0.3511,  0.1406,  0.0523,  0.5282,  0.0649,  0.2315,  0.8829,  0.4588,\n         0.0370,  0.4487,  0.4330,  0.5806,  0.4239,  0.4433,  0.4272,  0.3340,\n         0.4389,  0.0978,  0.1303,  0.1124,  0.1552, -0.0097,  0.2695,  0.0611,\n         0.2841,  0.1736,  0.0882,  0.2791,  0.0051, -0.0186,  0.3026,  0.1888,\n         0.1807,  0.1591,  0.2379,  0.0516,  0.1096,  0.0139,  0.2764,  0.1140,\n         0.0953, -0.0779, -0.1112,  0.1059,  0.0351,  0.1636,  0.2241,  0.0975],\n       device='cuda:0', grad_fn=<SelectBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"以下结果说明，第 1 个问答中，第 306 个 token 最有可能是 start","metadata":{"id":"lNuIY6ukFSnf"}},{"cell_type":"code","source":"torch.argmax(outputs.start_logits, dim=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBsLnYBTEMDp","outputId":"a1d78c43-0ad0-4303-c635-2feae4f6c58f","execution":{"iopub.status.busy":"2023-04-16T13:16:20.899543Z","iopub.execute_input":"2023-04-16T13:16:20.900291Z","iopub.status.idle":"2023-04-16T13:16:20.909278Z","shell.execute_reply.started":"2023-04-16T13:16:20.900253Z","shell.execute_reply":"2023-04-16T13:16:20.908168Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"tensor([ 22, 296, 332, 306, 349, 365, 340,  66], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"start_pred = torch.argmax(outputs.start_logits, dim=1)\nend_pred = torch.argmax(outputs.end_logits, dim=1)","metadata":{"id":"XOlVfrfJGKJA","execution":{"iopub.status.busy":"2023-04-16T13:16:20.910890Z","iopub.execute_input":"2023-04-16T13:16:20.911827Z","iopub.status.idle":"2023-04-16T13:16:20.918162Z","shell.execute_reply.started":"2023-04-16T13:16:20.911789Z","shell.execute_reply":"2023-04-16T13:16:20.917327Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"start_pred","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCgnLNW6GLVz","outputId":"85cfac89-4919-4ab5-b22c-c59c716ac6bd","execution":{"iopub.status.busy":"2023-04-16T13:16:20.919853Z","iopub.execute_input":"2023-04-16T13:16:20.920223Z","iopub.status.idle":"2023-04-16T13:16:20.929290Z","shell.execute_reply.started":"2023-04-16T13:16:20.920187Z","shell.execute_reply":"2023-04-16T13:16:20.928431Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"tensor([ 22, 296, 332, 306, 349, 365, 340,  66], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"end_pred","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugKtENtzGNfY","outputId":"3836dd89-fc0c-4583-ccc6-7d18ccf17dcb","execution":{"iopub.status.busy":"2023-04-16T13:16:20.931004Z","iopub.execute_input":"2023-04-16T13:16:20.931563Z","iopub.status.idle":"2023-04-16T13:16:20.940167Z","shell.execute_reply.started":"2023-04-16T13:16:20.931527Z","shell.execute_reply":"2023-04-16T13:16:20.939154Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"tensor([424, 357, 270, 124,  39, 380,   1,  21], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"if fp16_training:\n    model, optim, train_loader = accelerator.prepare(model, optim, train_loader)\n    \nmodel.train()\nfor epoch in range(3):\n    loss_sum = 0.0\n    acc_start_sum = 0.0\n    acc_end_sum = 0.0\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n    for batch_idx, batch in enumerate(pbar):\n        optim.zero_grad()\n        \n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        start_positions = batch['start_positions']\n        end_positions = batch['end_positions']\n        \n        outputs = model(input_ids, attention_mask=attention_mask, \n                        start_positions=start_positions, \n                        end_positions=end_positions)\n        \n        loss = outputs.loss\n        if fp16_training:\n            accelerator.backward(loss)\n        else:\n            loss.backward()\n        optim.step()\n        \n        loss_sum += loss.item()\n        \n        ### START CODE HERE ### \n        # Obtain answer by choosing the most probable start position / end position\n        # Using `torch.argmax` and its `dim` parameter to extract preditions for start position and end position.\n        start_pred = torch.argmax(outputs.start_logits, dim=1)\n        end_pred = torch.argmax(outputs.end_logits, dim=1)\n        \n        # calculate accuracy for start and end positions. eg., using start_pred and start_positions to calculate acc_start.\n        acc_start = (start_pred == start_positions).float().mean()\n        acc_end = (end_pred == end_positions).float().mean()\n        ### END CODE HERE ### \n        \n        acc_start_sum += acc_start\n        acc_end_sum += acc_end\n        \n        # Update progress bar\n        postfix = {\n            \"loss\": f\"{loss_sum/(batch_idx+1):.4f}\",\n            \"acc_start\": f\"{acc_start_sum/(batch_idx+1):.4f}\",\n            \"acc_end\": f\"{acc_end_sum/(batch_idx+1):.4f}\"\n        }\n\n        # Add batch accuracy to progress bar\n        batch_desc = f\"Epoch {epoch}, train loss: {postfix['loss']}\"\n        pbar.set_postfix_str(f\"{batch_desc}, acc start: {postfix['acc_start']}, acc end: {postfix['acc_end']}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLRkqpVP--g0","outputId":"04d3f55a-4f51-4768-9e80-9a18b4b80a10","execution":{"iopub.status.busy":"2023-04-16T13:16:40.896013Z","iopub.execute_input":"2023-04-16T13:16:40.896742Z","iopub.status.idle":"2023-04-16T13:45:01.563452Z","shell.execute_reply.started":"2023-04-16T13:16:40.896695Z","shell.execute_reply":"2023-04-16T13:45:01.562345Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Epoch 0: 100%|██████████| 1268/1268 [09:27<00:00,  2.23it/s, Epoch 0, train loss: 2.0183, acc start: 0.4461, acc end: 0.4412]\nEpoch 1: 100%|██████████| 1268/1268 [09:26<00:00,  2.24it/s, Epoch 1, train loss: 1.2921, acc start: 0.5909, acc end: 0.5992]\nEpoch 2: 100%|██████████| 1268/1268 [09:26<00:00,  2.24it/s, Epoch 2, train loss: 0.9709, acc start: 0.6605, acc end: 0.6678]\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(doc, query):\n    print(doc)\n    print('提问：', query)\n    item = tokenizer([doc, query], max_length=512, return_tensors='pt', truncation=True, padding=True)\n    with torch.no_grad():\n        input_ids = item['input_ids'].to(device).reshape(1,-1)\n        attention_mask = item['attention_mask'].to(device).reshape(1,-1)\n        \n        outputs = model(input_ids[:, :512], attention_mask[:, :512])\n        \n        ### START CODE HERE ### \n        # Using `torch.argmax` and its `dim` parameter to extract preditions for start position and end position.\n        start_pred = torch.argmax(outputs.start_logits, dim=1)\n        end_pred = torch.argmax(outputs.end_logits, dim=1)\n        ### END CODE HERE ### \n    \n    try:\n        start_pred = item.token_to_chars(0, start_pred)\n        end_pred = item.token_to_chars(0, end_pred)\n    except:\n        return ''\n    \n    if start_pred.start > end_pred.end:\n        return ''\n    else:\n        return doc[start_pred.start:end_pred.end]","metadata":{"tags":[],"id":"unZT1GHn4yOx","execution":{"iopub.status.busy":"2023-04-16T14:13:34.474729Z","iopub.execute_input":"2023-04-16T14:13:34.475954Z","iopub.status.idle":"2023-04-16T14:13:34.485041Z","shell.execute_reply.started":"2023-04-16T14:13:34.475909Z","shell.execute_reply":"2023-04-16T14:13:34.483930Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"dev['data'][100]","metadata":{"tags":[],"id":"YUIztgBv4yOx","outputId":"8cc460e9-80cf-4b74-81e6-04dbb2cff8cb","execution":{"iopub.status.busy":"2023-04-16T14:05:00.722175Z","iopub.execute_input":"2023-04-16T14:05:00.722556Z","iopub.status.idle":"2023-04-16T14:05:00.731236Z","shell.execute_reply.started":"2023-04-16T14:05:00.722522Z","shell.execute_reply":"2023-04-16T14:05:00.730076Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"{'paragraphs': [{'id': 'DEV_109',\n   'context': '岑朗天（），笔名朗天、霍惊觉。香港作家、影评人、文化活动策划、大学兼职讲师。香港新亚研究所硕士，师从牟宗三，父亲为香港专栏作家昆南。曾在香港多家报社从事繙译、编辑、采访工作。1995年加入香港电影评论学会，并于2003-2007年出任该会会长，2016年退出。1995年参与创立新研哲学会，后易名香港人文哲学会，再易名香港人文学会。1998年加入树宁．现在式单位，出任该剧团董事及编剧。2003年担任牛棚书展（2003-6）统筹，协助开拓主流以外的书展文化（牛棚书展精神后为九龙城书节继承）。2004年6月至2011年加入商业电台光明顶，担任嘉宾主持。2004年至2014年于香港中文大学新闻与传播学院兼职教授媒体创意写作。2012年始兼任香港浸会大学电影学院讲师，教授文学与影视相关课程。',\n   'qas': [{'question': '岑朗天笔名叫什么？',\n     'id': 'DEV_109_QUERY_0',\n     'answers': [{'text': '朗天、霍惊觉', 'answer_start': 8},\n      {'text': '朗天、霍惊觉', 'answer_start': 8},\n      {'text': '朗天、霍惊觉', 'answer_start': 8}]},\n    {'question': '岑朗天的职业都有哪些？',\n     'id': 'DEV_109_QUERY_1',\n     'answers': [{'text': '作家、影评人、文化活动策划、大学兼职讲师', 'answer_start': 17},\n      {'text': '作家、影评人、文化活动策划、大学兼职讲师', 'answer_start': 17},\n      {'text': '作家、影评人、文化活动策划、大学兼职讲师', 'answer_start': 17}]},\n    {'question': '岑朗天哪年加入香港电影评论学会？',\n     'id': 'DEV_109_QUERY_2',\n     'answers': [{'text': '1995年', 'answer_start': 87},\n      {'text': '1995年', 'answer_start': 87},\n      {'text': '1995年', 'answer_start': 87}]},\n    {'question': '2004年6月至2011年，岑朗天在什么地方担任嘉宾主持？',\n     'id': 'DEV_109_QUERY_3',\n     'answers': [{'text': '商业电台光明顶', 'answer_start': 261},\n      {'text': '商业电台光明顶', 'answer_start': 261},\n      {'text': '商业电台光明顶', 'answer_start': 261}]},\n    {'question': '2004年至2014年，岑朗天在香港中文大学哪个学院教授课程？',\n     'id': 'DEV_109_QUERY_4',\n     'answers': [{'text': '新闻与传播学院', 'answer_start': 294},\n      {'text': '新闻与传播学院', 'answer_start': 294},\n      {'text': '新闻与传播学院', 'answer_start': 294}]}]}],\n 'id': 'DEV_109',\n 'title': '岑朗天'}"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\npredict(dev['data'][100]['paragraphs'][0]['context'],\n       dev['data'][100]['paragraphs'][0]['qas'][0]['question'])","metadata":{"tags":[],"id":"vAgxwNam4yOx","outputId":"ab98d157-3b6c-4ac4-fc31-071052452bfd","execution":{"iopub.status.busy":"2023-04-16T14:13:38.275622Z","iopub.execute_input":"2023-04-16T14:13:38.276592Z","iopub.status.idle":"2023-04-16T14:13:38.312836Z","shell.execute_reply.started":"2023-04-16T14:13:38.276527Z","shell.execute_reply":"2023-04-16T14:13:38.311694Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"岑朗天（），笔名朗天、霍惊觉。香港作家、影评人、文化活动策划、大学兼职讲师。香港新亚研究所硕士，师从牟宗三，父亲为香港专栏作家昆南。曾在香港多家报社从事繙译、编辑、采访工作。1995年加入香港电影评论学会，并于2003-2007年出任该会会长，2016年退出。1995年参与创立新研哲学会，后易名香港人文哲学会，再易名香港人文学会。1998年加入树宁．现在式单位，出任该剧团董事及编剧。2003年担任牛棚书展（2003-6）统筹，协助开拓主流以外的书展文化（牛棚书展精神后为九龙城书节继承）。2004年6月至2011年加入商业电台光明顶，担任嘉宾主持。2004年至2014年于香港中文大学新闻与传播学院兼职教授媒体创意写作。2012年始兼任香港浸会大学电影学院讲师，教授文学与影视相关课程。\n提问： 岑朗天笔名叫什么？\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"'朗天、霍惊觉'"},"metadata":{}}]},{"cell_type":"code","source":"doc='温开宇在美国波士顿大学读数理金融和金融科技硕士，他的身高是193厘米。'","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:47:17.371116Z","iopub.execute_input":"2023-04-16T14:47:17.371736Z","iopub.status.idle":"2023-04-16T14:47:17.376422Z","shell.execute_reply.started":"2023-04-16T14:47:17.371697Z","shell.execute_reply":"2023-04-16T14:47:17.375297Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"predict(\n    doc=doc,\n    query='温开宇在哪个大学？'\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:47:35.690925Z","iopub.execute_input":"2023-04-16T14:47:35.691984Z","iopub.status.idle":"2023-04-16T14:47:35.713224Z","shell.execute_reply.started":"2023-04-16T14:47:35.691939Z","shell.execute_reply":"2023-04-16T14:47:35.712172Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"温开宇在美国波士顿大学读数理金融和金融科技硕士，他的身高是193厘米。\n提问： 温开宇在哪个大学？\n","output_type":"stream"},{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"'美国波士顿大学'"},"metadata":{}}]},{"cell_type":"code","source":"predict(\n    doc=doc,\n    query='温开宇读什么专业？'\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:47:49.765992Z","iopub.execute_input":"2023-04-16T14:47:49.766935Z","iopub.status.idle":"2023-04-16T14:47:49.786993Z","shell.execute_reply.started":"2023-04-16T14:47:49.766881Z","shell.execute_reply":"2023-04-16T14:47:49.785852Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"温开宇在美国波士顿大学读数理金融和金融科技硕士，他的身高是193厘米。\n提问： 温开宇读什么专业？\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"'数理金融和金融科技硕士'"},"metadata":{}}]},{"cell_type":"code","source":"predict(\n    doc=doc,\n    query='温开宇多高？'\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:48:00.930847Z","iopub.execute_input":"2023-04-16T14:48:00.931244Z","iopub.status.idle":"2023-04-16T14:48:00.951068Z","shell.execute_reply.started":"2023-04-16T14:48:00.931208Z","shell.execute_reply":"2023-04-16T14:48:00.949845Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"温开宇在美国波士顿大学读数理金融和金融科技硕士，他的身高是193厘米。\n提问： 温开宇多高？\n","output_type":"stream"},{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"'193厘米'"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"./fengchao-bert-qa\", from_pt=True) ","metadata":{"execution":{"iopub.status.busy":"2023-04-16T15:05:32.748853Z","iopub.execute_input":"2023-04-16T15:05:32.749245Z","iopub.status.idle":"2023-04-16T15:05:33.329118Z","shell.execute_reply.started":"2023-04-16T15:05:32.749209Z","shell.execute_reply":"2023-04-16T15:05:33.328021Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"model_load_from_file = BertForQuestionAnswering.from_pretrained('./fengchao-bert-qa').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T15:06:49.734283Z","iopub.execute_input":"2023-04-16T15:06:49.735459Z","iopub.status.idle":"2023-04-16T15:06:51.118662Z","shell.execute_reply.started":"2023-04-16T15:06:49.735399Z","shell.execute_reply":"2023-04-16T15:06:51.117617Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"model_load_from_file","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_local(doc, query):\n    print(doc)\n    print('提问：', query)\n    item = tokenizer([doc, query], max_length=512, return_tensors='pt', truncation=True, padding=True)\n    with torch.no_grad():\n        input_ids = item['input_ids'].to(device).reshape(1,-1)\n        attention_mask = item['attention_mask'].to(device).reshape(1,-1)\n        \n        outputs = model_load_from_file(input_ids[:, :512], attention_mask[:, :512])\n        \n        ### START CODE HERE ### \n        # Using `torch.argmax` and its `dim` parameter to extract preditions for start position and end position.\n        start_pred = torch.argmax(outputs.start_logits, dim=1)\n        end_pred = torch.argmax(outputs.end_logits, dim=1)\n        ### END CODE HERE ### \n    \n    try:\n        start_pred = item.token_to_chars(0, start_pred)\n        end_pred = item.token_to_chars(0, end_pred)\n    except:\n        return ''\n    \n    if start_pred.start > end_pred.end:\n        return ''\n    else:\n        return doc[start_pred.start:end_pred.end]","metadata":{"execution":{"iopub.status.busy":"2023-04-16T15:08:08.694390Z","iopub.execute_input":"2023-04-16T15:08:08.695411Z","iopub.status.idle":"2023-04-16T15:08:08.703808Z","shell.execute_reply.started":"2023-04-16T15:08:08.695369Z","shell.execute_reply":"2023-04-16T15:08:08.702641Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"predict_local(\n    doc=doc,\n    query='温开宇多高？'\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T15:08:28.188518Z","iopub.execute_input":"2023-04-16T15:08:28.188905Z","iopub.status.idle":"2023-04-16T15:08:28.210266Z","shell.execute_reply.started":"2023-04-16T15:08:28.188870Z","shell.execute_reply":"2023-04-16T15:08:28.209157Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"温开宇在美国波士顿大学读数理金融和金融科技硕士，他的身高是193厘米。\n提问： 温开宇多高？\n","output_type":"stream"},{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"'193厘米'"},"metadata":{}}]},{"cell_type":"code","source":"!du -h fengchao-bert-qa","metadata":{"execution":{"iopub.status.busy":"2023-04-16T15:12:35.368586Z","iopub.execute_input":"2023-04-16T15:12:35.369259Z","iopub.status.idle":"2023-04-16T15:12:36.426278Z","shell.execute_reply.started":"2023-04-16T15:12:35.369216Z","shell.execute_reply":"2023-04-16T15:12:36.425041Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n388M\tfengchao-bert-qa\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Open Questions\n可以查阅相关资料，并完成如下开放式的问答题。\n","metadata":{"id":"TZzWaC8q4yOx"}},{"cell_type":"markdown","source":"- 我们使用了512长度的Bert，但是在实际应用中，输入长度可能大于512，你想怎么解决这个问题，请描述你的算法，在训练和预测时分别采取什么样的方法。（假设问题的长度都满足小于512token，段落的长度可能大于512token，以QA问题为例）\n","metadata":{"id":"t5Q4n_UA4yOx"}},{"cell_type":"markdown","source":"Your Answer:","metadata":{"id":"yAbMYlQG4yOy"}},{"cell_type":"markdown","source":"- 在输出中，我们分别对start_pred和end_pred的位置进行预估，如果end_pred<start_pred，我们可以如何解决这样的问题?","metadata":{"id":"9hGXhdfr4yOy"}},{"cell_type":"markdown","source":"Your Answer:","metadata":{"id":"94R7Dtc84yOy"}},{"cell_type":"markdown","source":"- Bert的分词方式是什么?在中文中，你觉得这样的方式会带来什么问题？什么样的分词方式适合中文？在中文的文本上，除了改变分词方式，还有哪些方式可以提升模型效果？\n\n阅读资料：https://github.com/ymcui/Chinese-BERT-wwm","metadata":{"id":"1Hd2Wq9j4yOy"}},{"cell_type":"markdown","source":"Your Answer:","metadata":{"id":"EazfnlFe4yOy"}}]}